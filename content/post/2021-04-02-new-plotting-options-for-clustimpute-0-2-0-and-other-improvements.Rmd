---
title: New plot functionality for ClustImpute 0.2.0 and other improvements
author: Oliver Pfaffel
date: '2021-04-02'
slug: new-plotting-options-for-clustimpute-0-2-0-and-other-improvements
categories:
  - R
  - unsupervised machine learning
  - statistical analysis
tags:
  - dataviz
  - clustering
  - k-means
  - missing data
description: ''
thumbnail: ''
---

Let's create some dummy data...

```{r}
### Random Dataset
set.seed(739)
n <- 7500 # numer of points
nr_other_vars <- 4
mat <- matrix(rnorm(nr_other_vars*n),n,nr_other_vars)
me<-4 # mean
x <- c(rnorm(n/3,me/2,1),rnorm(2*n/3,-me/2,1)) 
y <- c(rnorm(n/3,0,1),rnorm(n/3,me,1),rnorm(n/3,-me,1))
true_clust <- c(rep(1,n/3),rep(2,n/3),rep(3,n/3)) # true clusters
dat <- cbind(mat,x,y)
dat<- as.data.frame(scale(dat)) # scaling
summary(dat)
```

...with missings...

```{r}
library(ClustImpute)
dat_with_miss <- miss_sim(dat,p=.2,seed_nr=120)
mis_ind <- is.na(dat_with_miss) # missing indicator
```


...that is clearly hard to impute using a simple random imputation:

```{r echo=FALSE, warning=FALSE,message=FALSE}
library(Hmisc)
library(ggExtra)
dat_random_imp <- dat_with_miss
for (j in 1:dim(dat)[2]) {
  dat_random_imp[,j] <- impute(dat_random_imp[,j],fun="random")
}
imp <- factor(pmax(mis_ind[,5],mis_ind[,6]),labels=c("Original","Imputed")) # point is imputed if x or y is imputed
p_random_imp <- ggplot(dat_random_imp) + geom_point(aes(x=x,y=y,color=imp))
ggMarginal(p_random_imp,groupColour = TRUE, groupFill = TRUE)
```

Any clustering based on data "completed" this way will not provide good results. With ClustImpute we come a bit closer to a clustering based on the the full data as we can see here:

```{r echo=FALSE, warning=FALSE,message=FALSE}
nr_iter <- 10 # iterations of procedure
n_end <- 10 # step until convergence of weight function to 1
nr_cluster <- 3 # number of clusters
c_steps <- 50 # numer of cluster steps per iteration
res <- ClustImpute(dat_with_miss,nr_cluster=nr_cluster, nr_iter=nr_iter, c_steps=c_steps, n_end=n_end) 
p_clustimpute <- ggplot(res$complete_data,aes(x,y,color=factor(res$clusters))) + geom_point()
ggMarginal(p_clustimpute,groupColour = TRUE, groupFill = TRUE)
```

How would we look at the cluster results if we did not knew that the clusters exist in a 2-dimensional subspace? One way would be to look at the marginal distribution of each features within a cluster. Basically what is shown above by making use of the ggExtra package. ClustImpute has this now as build-in default plot:

```{r fig.width=10, fig.height=7}
plot(res)+xlim(-2.5,2.5)
```

We trunctate the x-axis here to focus on the body of the distribution but of course this is optional. Clearly, the clusters only really differ by feature x and y. The orange bars show the cluster centroids - alternatively one can also show the mean of all data points grouped by cluster and feature (which may differ slightly since the last step in ClustImpute is the cluster assignment based on the final centroids).

Alternatively one can also visualize the marginal distributions with a box-plot:

```{r fig.width=10, fig.height=7}
plot(res, type="box")
```

### Other new functionality

There are some other new features - perhaps there are separate posts following up on those.

* It used to be the (strong) recommendation to center the data if a weight function is used (n_end >1). Now, by default, the scaling with the weight function is towards the global overall mean of each feature. Thus, for centered data there is almost no change (due the random imputation mechanism data with a true unknown mean of zero might have an empirical mean unequal to zero). This is relevant for you if you have to work with uncentered data for whatever (good) reason.
* There is a check if the data is centered, and potentially a warning (if you scale the imputed values towards zero instead of the actual mean).
* Added custom print function showing clsuter centrois and number of observations per cluster in nicely formated tables. Nothing dramatic but nice to look at.

